"""
í†µí•© íƒ€ì„ë¼ì¸ ìƒì„±ê¸° - ì´ë©”ì¼ê³¼ ì¶”ê°€ ì¦ê±°ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ í†µí•©
Integrated Timeline Generator for Court Submission

ì´ë©”ì¼ê³¼ ì¶”ê°€ ì¦ê±° ìë£Œë¥¼ ë°œìƒ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í†µí•©í•˜ì—¬
ë²•ì› ì œì¶œìš© ì‹œê°„ìˆœ íƒ€ì„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
import shutil
import zipfile
from datetime import date, datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union


class IntegratedTimelineGenerator:
    """í†µí•© íƒ€ì„ë¼ì¸ ìƒì„±ê¸°"""

    def __init__(self, base_dir: str = "processed_emails"):
        self.base_dir = Path(base_dir)
        self.timeline_dir = self.base_dir / "06_í†µí•©íƒ€ì„ë¼ì¸"
        self.timeline_dir.mkdir(exist_ok=True)

    def generate_integrated_timeline(self) -> Dict:
        """ì´ë©”ì¼ê³¼ ì¶”ê°€ ì¦ê±°ë¥¼ í†µí•©í•œ íƒ€ì„ë¼ì¸ ìƒì„±"""
        print("ğŸ“… í†µí•© íƒ€ì„ë¼ì¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("=" * 60)

        timeline_items = []

        # 1. ì´ë©”ì¼ ë°ì´í„° ìˆ˜ì§‘
        email_items = self._collect_email_timeline_data()
        timeline_items.extend(email_items)
        print(f"  ğŸ“§ ì´ë©”ì¼ í•­ëª©: {len(email_items)}ê°œ")

        # 2. ì¶”ê°€ ì¦ê±° ë°ì´í„° ìˆ˜ì§‘
        additional_items = self._collect_additional_evidence_data()
        timeline_items.extend(additional_items)
        print(f"  ğŸ“ ì¶”ê°€ ì¦ê±° í•­ëª©: {len(additional_items)}ê°œ")

        # 3. ì‹œê°„ìˆœ ì •ë ¬
        timeline_items.sort(key=lambda x: x['event_date'])
        print(f"  ğŸ“‹ ì´ íƒ€ì„ë¼ì¸ í•­ëª©: {len(timeline_items)}ê°œ")

        # 4. íƒ€ì„ë¼ì¸ ë³´ê³ ì„œ ìƒì„±
        timeline_report = self._generate_timeline_report(timeline_items)

        # 5. ë²•ì› ì œì¶œìš© íŒ¨í‚¤ì§€ ìƒì„±
        self._create_court_submission_package(timeline_items)

        # 6. Excel íŒŒì¼ ìƒì„±
        excel_path = self._generate_excel_timeline(timeline_items)

        print("âœ… í†µí•© íƒ€ì„ë¼ì¸ ìƒì„± ì™„ë£Œ!")
        return {
            'total_items': len(timeline_items),
            'email_items': len(email_items),
            'additional_items': len(additional_items),
            'timeline_items': timeline_items,
            'excel_path': str(excel_path),
            'timeline_report': timeline_report
        }

    def _collect_email_timeline_data(self) -> List[Dict]:
        """ì´ë©”ì¼ íƒ€ì„ë¼ì¸ ë°ì´í„° ìˆ˜ì§‘"""
        email_items = []

        # ì²˜ë¦¬ëœ ì´ë©”ì¼ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
        for email_dir in self.base_dir.glob("[*]_*"):
            if not email_dir.is_dir():
                continue

            try:
                # ì´ë©”ì¼ ë©”íƒ€ë°ì´í„° ì°¾ê¸°
                metadata_files = list(email_dir.glob("*metadata*.json"))
                if not metadata_files:
                    continue

                with open(metadata_files[0], 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                # ì´ë©”ì¼ ë°œì†¡ ë‚ ì§œ íŒŒì‹±
                email_date = self._parse_email_date(metadata.get('date', ''))
                if not email_date:
                    continue

                # ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                attachments = []
                attachments_dir = email_dir / "ì²¨ë¶€íŒŒì¼"
                if attachments_dir.exists():
                    for attachment_file in attachments_dir.iterdir():
                        if attachment_file.is_file():
                            attachments.append({
                                'name': attachment_file.name,
                                'size': attachment_file.stat().st_size,
                                'path': str(attachment_file.relative_to(self.base_dir))
                            })

                # ì¦ê±° íŒŒì¼ ê²½ë¡œ
                evidence_files = []
                pdf_files = list(email_dir.glob("*.pdf"))
                html_files = list(email_dir.glob("*.html"))

                for pdf_file in pdf_files:
                    evidence_files.append({
                        'type': 'PDF',
                        'name': pdf_file.name,
                        'path': str(pdf_file.relative_to(self.base_dir))
                    })

                for html_file in html_files:
                    evidence_files.append({
                        'type': 'HTML',
                        'name': html_file.name,
                        'path': str(html_file.relative_to(self.base_dir))
                    })

                email_item = {
                    'type': 'EMAIL',
                    'event_date': email_date,
                    'event_time': email_date.strftime('%H:%M:%S') if hasattr(email_date, 'hour') else '00:00:00',
                    'title': metadata.get('subject', 'ì œëª© ì—†ìŒ'),
                    'description': f"ë°œì‹ ì: {metadata.get('from', 'N/A')}\nìˆ˜ì‹ ì: {metadata.get('to', 'N/A')}",
                    'participants': {
                        'from': metadata.get('from', 'N/A'),
                        'to': metadata.get('to', 'N/A'),
                        'cc': metadata.get('cc', ''),
                        'bcc': metadata.get('bcc', '')
                    },
                    'attachments': attachments,
                    'evidence_files': evidence_files,
                    'folder_name': email_dir.name,
                    'message_id': metadata.get('message_id', ''),
                    'importance': self._determine_email_importance(metadata, attachments)
                }

                email_items.append(email_item)

            except Exception as e:
                print(f"  âš ï¸ ì´ë©”ì¼ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜ ({email_dir.name}): {str(e)}")
                continue

        return email_items

    def _collect_additional_evidence_data(self) -> List[Dict]:
        """ì¶”ê°€ ì¦ê±° íƒ€ì„ë¼ì¸ ë°ì´í„° ìˆ˜ì§‘"""
        additional_items = []

        additional_evidence_dir = self.base_dir / "05_ì¶”ê°€ì¦ê±°"
        if not additional_evidence_dir.exists():
            return additional_items

        metadata_file = additional_evidence_dir / "ì¶”ê°€ì¦ê±°_ëª©ë¡.json"
        if not metadata_file.exists():
            return additional_items

        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            for file_id, file_info in metadata.get('files', {}).items():
                # ì¦ê±° ë°œìƒ ë‚ ì§œ íŒŒì‹±
                evidence_date = self._parse_evidence_date(
                    file_info.get('evidence_date', ''))
                if not evidence_date:
                    continue

                # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸
                file_path = self.base_dir / file_info['current_path']
                if not file_path.exists():
                    print(f"  âš ï¸ ì¶”ê°€ ì¦ê±° íŒŒì¼ ëˆ„ë½: {file_info['title']}")
                    continue

                additional_item = {
                    'type': 'ADDITIONAL_EVIDENCE',
                    'event_date': evidence_date,
                    'event_time': '00:00:00',  # ì¶”ê°€ ì¦ê±°ëŠ” ë³´í†µ ì •í™•í•œ ì‹œê°„ì´ ì—†ìŒ
                    'title': file_info['title'],
                    'description': file_info.get('description', ''),
                    'category': file_info.get('category_name', 'ê¸°íƒ€'),
                    'evidence_number': file_info.get('evidence_number', ''),
                    'party': file_info.get('party', 'ê°‘'),
                    'file_info': {
                        'name': file_path.name,
                        'size': file_info['file_size'],
                        'type': file_info.get('mime_type', ''),
                        'path': file_info['current_path'],
                        'hash': file_info['file_hash']
                    },
                    'related_emails': file_info.get('related_email_ids', []),
                    'importance': self._determine_evidence_importance(file_info)
                }

                additional_items.append(additional_item)

        except Exception as e:
            print(f"  âš ï¸ ì¶”ê°€ ì¦ê±° ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")

        return additional_items

    def _parse_email_date(self, date_str: str) -> Optional[datetime]:
        """ì´ë©”ì¼ ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        if not date_str:
            return None

        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì§€ì›
        date_formats = [
            '%a, %d %b %Y %H:%M:%S %z',
            '%a, %d %b %Y %H:%M:%S',
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d',
            '%d/%m/%Y %H:%M:%S',
            '%d/%m/%Y'
        ]

        for fmt in date_formats:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except ValueError:
                continue

        # RFC 2822 í˜•ì‹ ì²˜ë¦¬
        try:
            from email.utils import parsedate_to_datetime
            return parsedate_to_datetime(date_str)
        except:
            pass

        return None

    def _parse_evidence_date(self, date_str: str) -> Optional[date]:
        """ì¦ê±° ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        if not date_str:
            return None

        date_formats = ['%Y-%m-%d', '%d/%m/%Y', '%Y.%m.%d', '%Yë…„ %mì›” %dì¼']

        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(date_str.strip(), fmt)
                return parsed_date.date()
            except ValueError:
                continue

        return None

    def _determine_email_importance(self, metadata: Dict, attachments: List) -> str:
        """ì´ë©”ì¼ ì¤‘ìš”ë„ íŒë‹¨"""
        # ì²¨ë¶€íŒŒì¼ì´ ë§ìœ¼ë©´ ì¤‘ìš”
        if len(attachments) >= 3:
            return 'HIGH'

        # ì œëª©ì— ì¤‘ìš” í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´
        subject = metadata.get('subject', '').lower()
        important_keywords = ['ê³„ì•½', 'í•©ì˜', 'ì¤‘ìš”', 'ê¸´ê¸‰', 'ë²•ì ', 'ì†Œì†¡', 'ê³ ë°œ', 'ì‹ ê³ ']
        if any(keyword in subject for keyword in important_keywords):
            return 'HIGH'

        # ì²¨ë¶€íŒŒì¼ì´ ìˆìœ¼ë©´ ë³´í†µ
        if len(attachments) > 0:
            return 'MEDIUM'

        return 'LOW'

    def _determine_evidence_importance(self, file_info: Dict) -> str:
        """ì¶”ê°€ ì¦ê±° ì¤‘ìš”ë„ íŒë‹¨"""
        # ê³„ì•½ì„œ, ë²•ì  ë¬¸ì„œëŠ” ë†’ìŒ
        title = file_info.get('title', '').lower()
        description = file_info.get('description', '').lower()

        high_keywords = ['ê³„ì•½ì„œ', 'í•©ì˜ì„œ', 'ë²•ì ', 'ì†Œì†¡', 'íŒê²°', 'ê²°ì •', 'ëª…ë ¹']
        if any(keyword in title or keyword in description for keyword in high_keywords):
            return 'HIGH'

        # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš° (ë¬¸ì„œë‚˜ ì˜ìƒ ë“±)
        if file_info.get('file_size', 0) > 10 * 1024 * 1024:  # 10MB ì´ìƒ
            return 'MEDIUM'

        return 'MEDIUM'  # ì¶”ê°€ ì¦ê±°ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì¤‘ìš”

    def _generate_timeline_report(self, timeline_items: List[Dict]) -> Dict:
        """íƒ€ì„ë¼ì¸ ë³´ê³ ì„œ ìƒì„±"""
        if not timeline_items:
            return {'summary': 'íƒ€ì„ë¼ì¸ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.'}

        # ê¸°ê°„ ê³„ì‚°
        start_date = min(item['event_date'] for item in timeline_items)
        end_date = max(item['event_date'] for item in timeline_items)

        if isinstance(start_date, datetime):
            start_date = start_date.date()
        if isinstance(end_date, datetime):
            end_date = end_date.date()

        duration = (end_date - start_date).days

        # ìœ í˜•ë³„ í†µê³„
        email_count = len(
            [item for item in timeline_items if item['type'] == 'EMAIL'])
        evidence_count = len(
            [item for item in timeline_items if item['type'] == 'ADDITIONAL_EVIDENCE'])

        # ì¤‘ìš”ë„ë³„ í†µê³„
        high_importance = len(
            [item for item in timeline_items if item['importance'] == 'HIGH'])
        medium_importance = len(
            [item for item in timeline_items if item['importance'] == 'MEDIUM'])
        low_importance = len(
            [item for item in timeline_items if item['importance'] == 'LOW'])

        report = {
            'summary': f"{start_date}ë¶€í„° {end_date}ê¹Œì§€ {duration}ì¼ê°„ì˜ íƒ€ì„ë¼ì¸",
            'period': {
                'start_date': str(start_date),
                'end_date': str(end_date),
                'duration_days': duration
            },
            'statistics': {
                'total_items': len(timeline_items),
                'email_count': email_count,
                'evidence_count': evidence_count,
                'high_importance': high_importance,
                'medium_importance': medium_importance,
                'low_importance': low_importance
            }
        }

        return report

    def _create_court_submission_package(self, timeline_items: List[Dict]):
        """ë²•ì› ì œì¶œìš© íŒ¨í‚¤ì§€ ìƒì„± (ì‹¤ì œ íŒŒì¼ í¬í•¨)"""
        print("ğŸ“¦ ë²•ì› ì œì¶œìš© íŒ¨í‚¤ì§€ ìƒì„± ì¤‘...")

        # íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
        package_dir = self.timeline_dir / \
            f"ë²•ì›ì œì¶œìš©_í†µí•©ì¦ê±°_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        package_dir.mkdir(exist_ok=True)

        # íƒ€ì„ë¼ì¸ ìˆœì„œë¡œ íŒŒì¼ ë³µì‚¬
        for i, item in enumerate(timeline_items, 1):
            item_dir = package_dir / \
                f"{i:03d}_{item['event_date']}_{item['type']}"
            item_dir.mkdir(exist_ok=True)

            # ì„¤ëª… íŒŒì¼ ìƒì„±
            info_file = item_dir / "ì¦ê±°ì •ë³´.txt"
            with open(info_file, 'w', encoding='utf-8') as f:
                f.write(f"ì¦ê±° ìˆœë²ˆ: {i}\n")
                f.write(f"ë°œìƒ ë‚ ì§œ: {item['event_date']}\n")
                f.write(f"ì¦ê±° ìœ í˜•: {item['type']}\n")
                f.write(f"ì œëª©: {item['title']}\n")
                f.write(f"ì„¤ëª…: {item['description']}\n")
                f.write(f"ì¤‘ìš”ë„: {item['importance']}\n\n")

                if item['type'] == 'EMAIL':
                    f.write("=== ì´ë©”ì¼ ì •ë³´ ===\n")
                    f.write(f"ë°œì‹ ì: {item['participants']['from']}\n")
                    f.write(f"ìˆ˜ì‹ ì: {item['participants']['to']}\n")
                    if item['participants']['cc']:
                        f.write(f"ì°¸ì¡°: {item['participants']['cc']}\n")
                    f.write(f"ë©”ì‹œì§€ ID: {item['message_id']}\n")

                    # ì²¨ë¶€íŒŒì¼ ì •ë³´
                    if item['attachments']:
                        f.write(f"\nì²¨ë¶€íŒŒì¼ ({len(item['attachments'])}ê°œ):\n")
                        for att in item['attachments']:
                            f.write(
                                f"  - {att['name']} ({att['size']} bytes)\n")

                    # ì¦ê±° íŒŒì¼ ë³µì‚¬
                    for evidence_file in item['evidence_files']:
                        source_path = self.base_dir / evidence_file['path']
                        if source_path.exists():
                            dest_path = item_dir / evidence_file['name']
                            shutil.copy2(source_path, dest_path)

                    # ì²¨ë¶€íŒŒì¼ ë³µì‚¬
                    attachments_dir = item_dir / "ì²¨ë¶€íŒŒì¼"
                    if item['attachments']:
                        attachments_dir.mkdir(exist_ok=True)
                        for att in item['attachments']:
                            source_path = self.base_dir / att['path']
                            if source_path.exists():
                                dest_path = attachments_dir / att['name']
                                shutil.copy2(source_path, dest_path)

                elif item['type'] == 'ADDITIONAL_EVIDENCE':
                    f.write("=== ì¶”ê°€ ì¦ê±° ì •ë³´ ===\n")
                    f.write(f"ì¦ê±°ë²ˆí˜¸: {item['evidence_number']}\n")
                    f.write(f"ì¹´í…Œê³ ë¦¬: {item['category']}\n")
                    f.write(f"ë‹¹ì‚¬ì: {item['party']}\n")
                    f.write(f"íŒŒì¼ í•´ì‹œ: {item['file_info']['hash']}\n")

                    if item['related_emails']:
                        f.write(
                            f"ê´€ë ¨ ì´ë©”ì¼: {', '.join(item['related_emails'])}\n")

                    # ì‹¤ì œ íŒŒì¼ ë³µì‚¬
                    source_path = self.base_dir / item['file_info']['path']
                    if source_path.exists():
                        dest_path = item_dir / item['file_info']['name']
                        shutil.copy2(source_path, dest_path)
                        f.write(f"\nì²¨ë¶€ëœ íŒŒì¼: {item['file_info']['name']}\n")

        print(f"  ğŸ“ íŒ¨í‚¤ì§€ ìƒì„± ì™„ë£Œ: {package_dir.name}")
        return str(package_dir)

    def _generate_excel_timeline(self, timeline_items: List[Dict]) -> Path:
        """Excel íƒ€ì„ë¼ì¸ ìƒì„±"""
        print("ğŸ“Š Excel íƒ€ì„ë¼ì¸ ìƒì„± ì¤‘...")

        # DataFrame ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        excel_data = []

        for i, item in enumerate(timeline_items, 1):
            row = {
                'ìˆœë²ˆ': i,
                'ë‚ ì§œ': str(item['event_date']),
                'ì‹œê°„': item['event_time'],
                'ìœ í˜•': 'ì´ë©”ì¼' if item['type'] == 'EMAIL' else 'ì¶”ê°€ì¦ê±°',
                'ì œëª©': item['title'],
                'ì„¤ëª…': item['description'][:100] + '...' if len(item['description']) > 100 else item['description'],
                'ì¤‘ìš”ë„': item['importance']
            }

            if item['type'] == 'EMAIL':
                row['ë°œì‹ ì'] = item['participants']['from']
                row['ìˆ˜ì‹ ì'] = item['participants']['to']
                row['ì²¨ë¶€íŒŒì¼ìˆ˜'] = len(item['attachments'])
                row['ì¦ê±°íŒŒì¼ìˆ˜'] = len(item['evidence_files'])
            else:
                row['ì¦ê±°ë²ˆí˜¸'] = item['evidence_number']
                row['ì¹´í…Œê³ ë¦¬'] = item['category']
                row['ë‹¹ì‚¬ì'] = item['party']
                row['íŒŒì¼í¬ê¸°'] = f"{item['file_info']['size'] / 1024:.1f} KB"

            excel_data.append(row)

        # openpyxlë¡œ Excel íŒŒì¼ ìƒì„±
        try:
            import openpyxl
        except ImportError:
            print("  âš ï¸  openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. Excel ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            # ì„ì‹œ ê²½ë¡œ ë°˜í™˜
            return self.timeline_dir / "timeline_excel_not_available.txt"

        excel_path = self.timeline_dir / \
            f"í†µí•©íƒ€ì„ë¼ì¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

        workbook = openpyxl.Workbook()

        # ë©”ì¸ íƒ€ì„ë¼ì¸ ì‹œíŠ¸ (ê¸°ë³¸ ì‹œíŠ¸ ì‚¬ìš©)
        ws_main = workbook.active
        if ws_main is not None:
            ws_main.title = 'í†µí•©íƒ€ì„ë¼ì¸'

        # í—¤ë” ì •ì˜
        headers = []
        if excel_data and ws_main is not None:
            headers = list(excel_data[0].keys())
            ws_main.append(headers)

            # ë°ì´í„° ì‘ì„±
            for row_data in excel_data:
                ws_main.append(list(row_data.values()))

        # ì´ë©”ì¼ë§Œ í•„í„°ë§ëœ ì‹œíŠ¸
        email_data = [row for row in excel_data if row['ìœ í˜•'] == 'ì´ë©”ì¼']
        if email_data and headers:
            ws_email = workbook.create_sheet('ì´ë©”ì¼íƒ€ì„ë¼ì¸')
            ws_email.append(headers)
            for row_data in email_data:
                ws_email.append(list(row_data.values()))

        # ì¶”ê°€ì¦ê±°ë§Œ í•„í„°ë§ëœ ì‹œíŠ¸
        evidence_data = [row for row in excel_data if row['ìœ í˜•'] == 'ì¶”ê°€ì¦ê±°']
        if evidence_data and headers:
            ws_evidence = workbook.create_sheet('ì¶”ê°€ì¦ê±°íƒ€ì„ë¼ì¸')
            ws_evidence.append(headers)
            for row_data in evidence_data:
                ws_evidence.append(list(row_data.values()))

        workbook.save(excel_path)

        print(f"  ğŸ“Š Excel íŒŒì¼ ìƒì„± ì™„ë£Œ: {excel_path.name}")
        return excel_path


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    generator = IntegratedTimelineGenerator()
    result = generator.generate_integrated_timeline()

    print(f"\nğŸ“‹ íƒ€ì„ë¼ì¸ ìƒì„± ê²°ê³¼:")
    print(f"  ì´ í•­ëª©: {result['total_items']}ê°œ")
    print(f"  ì´ë©”ì¼: {result['email_items']}ê°œ")
    print(f"  ì¶”ê°€ì¦ê±°: {result['additional_items']}ê°œ")
    print(f"  Excel íŒŒì¼: {result['excel_path']}")
